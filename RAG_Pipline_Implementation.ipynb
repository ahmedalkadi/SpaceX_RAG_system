{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Simple RAG System for SpaceX Projects\n",
        "## Part (2) Implement the RAG Pipeline  \n",
        "\\\n",
        "\n",
        "## Objective\n",
        "### Develop a basic Retrieval-Augmented Generation (RAG) system using different LLM models, embeddings, and libraries like LangChain to answer questions specifically related to SpaceX.\n",
        "\n",
        "The purpose of this step is to integrate various components such as data retrieval, embedding, and language models to build a robust RAG system that can handle queries efficiently.\n",
        "\n",
        "\\\n",
        "## Dataset Chunking\n",
        "In this step, datasets from different resources are collected and processed to create manageable chunks of text. The chunking process is tailored according to the requirements of the system, ensuring that each chunk is small enough for efficient retrieval but large enough to maintain context.\n",
        "\n",
        "\\\n",
        "### Resources Contributed:\n",
        "- **PDFs**: Mission guides, technical documents, and SpaceX fleet overviews.\n",
        "- **Wikipedia Articles**: Informative content about space exploration and rocket technology.\n",
        "- **News Articles**: Recent updates and journalism focusing on SpaceX's achievements.\n",
        "- **Video Transcripts**: Video content covering SpaceX’s technology and innovations.\n",
        "\n",
        "\\\n",
        "## Embedding the Chunks into Vectors\n",
        "After chunking the dataset, the text chunks are converted into vector representations. In this step, I used the `models/text-embedding-004` from **Gemini embeddings** due to its **high performance in capturing semantic relationships**. The model is chosen for its:\n",
        "\n",
        "- Ability to represent complex sentences accurately.\n",
        "- Lightweight nature, making it suitable for smaller-scale applications.\n",
        "- Good balance between computational cost and embedding quality.\n",
        "\n",
        "\\\n",
        "## Data Vectorizing\n",
        "To vectorize the data and build the vector database, I used **Chroma** for its **flexibility and ease of integration**. Chroma offers efficient vector storage and retrieval capabilities, making it a suitable choice for a retrieval-based pipeline. Its key features include:\n",
        "\n",
        "- **Scalability**: Suitable for handling larger datasets.\n",
        "- **Performance**: Optimized for fast vector searches.\n",
        "\n",
        "\\\n",
        "## LLM Models\n",
        "In this project, two models from **Gemini** were utilized: `gemini_pro 1.5` and `gemini_pro_flash 1.5`. The primary difference between the two is their **speed and memory efficiency**:\n",
        "\n",
        "- **Gemini Pro 1.5**: Offers high-quality generation and a deeper understanding of complex queries but might be slower for real-time applications.\n",
        "- **Gemini Pro Flash 1.5**: Prioritizes speed and resource efficiency, making it ideal for scenarios where quick responses are required, such as chatbots or real-time query handling.\n",
        "\n",
        "The user can select between these models depending on the trade-off between **response quality and speed**.\n"
      ],
      "metadata": {
        "id": "aonIy1a3XKO9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the required libraries"
      ],
      "metadata": {
        "id": "0rSCfe2Fg3RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download the required libraries\n",
        "\n",
        "!pip install --upgrade langchain google-generativeai\n",
        "\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jsFFzoN__6z7",
        "outputId": "841d3d81-e3ca-46cb-f8b4-38759d750cca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.3.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.7.2)\n",
            "Collecting google-generativeai\n",
            "  Downloading google_generativeai-0.8.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.4.0,>=0.3.6 (from langchain)\n",
            "  Downloading langchain_core-0.3.6-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.129-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting google-ai-generativelanguage==0.6.10 (from google-generativeai)\n",
            "  Downloading google_ai_generativelanguage-0.6.10-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.24.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.65.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.6->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (24.1)\n",
            "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m559.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Downloading langchain-0.3.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_generativeai-0.8.2-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.4/153.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_ai_generativelanguage-0.6.10-py3-none-any.whl (760 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.0/760.0 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.6-py3-none-any.whl (399 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.9/399.9 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.129-py3-none-any.whl (292 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.2/292.2 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenacity, orjson, jsonpointer, h11, jsonpatch, httpcore, httpx, langsmith, langchain-core, google-ai-generativelanguage, langchain-text-splitters, google-generativeai, langchain\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.6\n",
            "    Uninstalling google-ai-generativelanguage-0.6.6:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.6\n",
            "  Attempting uninstall: google-generativeai\n",
            "    Found existing installation: google-generativeai 0.7.2\n",
            "    Uninstalling google-generativeai-0.7.2:\n",
            "      Successfully uninstalled google-generativeai-0.7.2\n",
            "Successfully installed google-ai-generativelanguage-0.6.10 google-generativeai-0.8.2 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.1 langchain-core-0.3.6 langchain-text-splitters-0.3.0 langsmith-0.1.129 orjson-3.10.7 tenacity-8.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "c037dba55d7e4c0db8e1d63fc61ec8fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lK5l44IQWqQe",
        "outputId": "f8f4b531-f101-4ede-e92b-65bd57076d1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m604.0/604.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.5/294.5 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.2/249.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.0/385.0 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for durationpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.10/dist-packages (2.0.0)\n",
            "Requirement already satisfied: google-generativeai<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.7.2)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (2.9.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.6.6)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (3.20.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.24.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (0.1.129)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (8.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.23.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.65.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (3.10.7)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (3.1.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.2.2)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.10.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.1)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.129)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.1->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.1->langchain-community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.7)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain-community) (2.23.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.2)\n",
            "Downloading langchain_community-0.3.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-community-0.3.1 marshmallow-3.22.0 mypy-extensions-1.0.0 pydantic-settings-2.5.2 typing-inspect-0.9.0\n",
            "Collecting langchain-cohere\n",
            "  Downloading langchain_cohere-0.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: cohere<6.0,>=5.5.6 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere) (5.11.0)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere) (0.3.6)\n",
            "Collecting langchain-experimental>=0.3.0 (from langchain-cohere)\n",
            "  Downloading langchain_experimental-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pandas>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere) (2.1.4)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere) (2.9.2)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere) (0.9.0)\n",
            "Requirement already satisfied: boto3<2.0.0,>=1.34.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (1.35.29)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (1.9.7)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.27.2)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.4.0)\n",
            "Requirement already satisfied: parameterized<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.9.0)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.23.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.32.3)\n",
            "Requirement already satisfied: sagemaker<3.0.0,>=2.232.1 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.232.1)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.19.1)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.32.0.20240914)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-cohere) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-cohere) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-cohere) (0.1.129)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-cohere) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-cohere) (8.5.0)\n",
            "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-experimental>=0.3.0->langchain-cohere) (0.3.1)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain-cohere) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain-cohere) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain-cohere) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain-cohere) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-cohere) (0.7.0)\n",
            "Requirement already satisfied: botocore<1.36.0,>=1.35.29 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere) (1.35.29)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere) (0.10.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-cohere) (3.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (3.10.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (0.3.1)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (2.5.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-cohere) (3.10.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.3->langchain-cohere) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.5.6->langchain-cohere) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.5.6->langchain-cohere) (2.2.3)\n",
            "Requirement already satisfied: attrs<24,>=23.1.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (23.2.0)\n",
            "Requirement already satisfied: cloudpickle==2.2.1 in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (2.2.1)\n",
            "Requirement already satisfied: docker in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (7.1.0)\n",
            "Requirement already satisfied: google-pasta in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (0.2.0)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (6.11.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (4.23.0)\n",
            "Requirement already satisfied: pathos in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (0.3.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (4.3.6)\n",
            "Requirement already satisfied: protobuf<5.0,>=3.12 in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (5.9.5)\n",
            "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (1.0.9)\n",
            "Requirement already satisfied: schema in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (0.7.7)\n",
            "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (1.0.1)\n",
            "Requirement already satisfied: tblib<4,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (3.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (4.66.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (0.24.7)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (2024.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (3.20.2)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.1->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (0.3.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (1.0.1)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (13.8.1)\n",
            "Requirement already satisfied: mock<5.0,>4.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (4.0.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (0.20.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (3.1.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.2.2)\n",
            "Requirement already satisfied: ppft>=1.7.6.8 in /usr/local/lib/python3.10/dist-packages (from pathos->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (1.7.6.9)\n",
            "Requirement already satisfied: dill>=0.3.8 in /usr/local/lib/python3.10/dist-packages (from pathos->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (0.3.9)\n",
            "Requirement already satisfied: pox>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from pathos->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (0.3.5)\n",
            "Requirement already satisfied: multiprocess>=0.70.16 in /usr/local/lib/python3.10/dist-packages (from pathos->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (0.70.17)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (2.18.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (1.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (0.1.2)\n",
            "Downloading langchain_cohere-0.3.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_experimental-0.3.2-py3-none-any.whl (208 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-experimental, langchain-cohere\n",
            "Successfully installed langchain-cohere-0.3.0 langchain-experimental-0.3.2\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "unrar is already the newest version (1:6.1.5-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# install the required libraries\n",
        "\n",
        "! pip install -q --upgrade google-generativeai langchain-google-genai chromadb pypdf\n",
        "! pip install langchain-google-genai\n",
        "! pip install -U langchain-community\n",
        "! pip install gdown\n",
        "! apt-get install unrar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U langchain-cohere\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "M_SmlIvcLXnI",
        "outputId": "90a2d6d7-742a-4c10-9933-ec9a9dd25648"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-cohere in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: cohere<6.0,>=5.5.6 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere) (5.11.0)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere) (0.3.6)\n",
            "Requirement already satisfied: langchain-experimental>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere) (0.3.2)\n",
            "Requirement already satisfied: pandas>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere) (2.1.4)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere) (2.9.2)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere) (0.9.0)\n",
            "Requirement already satisfied: boto3<2.0.0,>=1.34.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (1.35.29)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (1.9.7)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.27.2)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.4.0)\n",
            "Requirement already satisfied: parameterized<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.9.0)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.23.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.32.3)\n",
            "Requirement already satisfied: sagemaker<3.0.0,>=2.232.1 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.232.1)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.19.1)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.32.0.20240914)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-cohere) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-cohere) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-cohere) (0.1.129)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-cohere) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-cohere) (8.5.0)\n",
            "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-experimental>=0.3.0->langchain-cohere) (0.3.1)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain-cohere) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain-cohere) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain-cohere) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain-cohere) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-cohere) (0.7.0)\n",
            "Requirement already satisfied: botocore<1.36.0,>=1.35.29 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere) (1.35.29)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere) (0.10.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-cohere) (3.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (3.10.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (0.3.1)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (2.5.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-cohere) (3.10.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.3->langchain-cohere) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.5.6->langchain-cohere) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.5.6->langchain-cohere) (2.2.3)\n",
            "Requirement already satisfied: attrs<24,>=23.1.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (23.2.0)\n",
            "Requirement already satisfied: cloudpickle==2.2.1 in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (2.2.1)\n",
            "Requirement already satisfied: docker in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (7.1.0)\n",
            "Requirement already satisfied: google-pasta in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (0.2.0)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (6.11.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (4.23.0)\n",
            "Requirement already satisfied: pathos in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (0.3.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (4.3.6)\n",
            "Requirement already satisfied: protobuf<5.0,>=3.12 in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (5.9.5)\n",
            "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (1.0.9)\n",
            "Requirement already satisfied: schema in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (0.7.7)\n",
            "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (1.0.1)\n",
            "Requirement already satisfied: tblib<4,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (3.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (4.66.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (0.24.7)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (2024.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (3.20.2)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.1->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (0.3.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (1.0.1)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (13.8.1)\n",
            "Requirement already satisfied: mock<5.0,>4.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (4.0.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (0.20.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (3.1.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.2.2)\n",
            "Requirement already satisfied: ppft>=1.7.6.8 in /usr/local/lib/python3.10/dist-packages (from pathos->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (1.7.6.9)\n",
            "Requirement already satisfied: dill>=0.3.8 in /usr/local/lib/python3.10/dist-packages (from pathos->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (0.3.9)\n",
            "Requirement already satisfied: pox>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from pathos->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (0.3.5)\n",
            "Requirement already satisfied: multiprocess>=0.70.16 in /usr/local/lib/python3.10/dist-packages (from pathos->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (0.70.17)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (2.18.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (1.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain-cohere) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the required functions\n",
        "\n",
        "from google.colab import drive\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA, LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "from chromadb import Client\n",
        "from chromadb.config import Settings\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "import textwrap\n",
        "import os\n",
        "import re\n",
        "\n",
        "import warnings\n"
      ],
      "metadata": {
        "id": "Zu9_NETVX8aA"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # this cell can be used if connected to  my drive\n",
        "\n",
        "# # mount my drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # change the divercory of working to RagProject folder to make it easier to work with the dirve\n",
        "# os.chdir(\"/content/drive/MyDrive/RagProject \")"
      ],
      "metadata": {
        "id": "9gyHGSwqZi7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## All available models my Gemini"
      ],
      "metadata": {
        "id": "ntkL5X0Ug_OX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# list all the available content generation models\n",
        "genai.configure(api_key=userdata.get(\"Gemini_API\"))\n",
        "\n",
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "_QrUMhIfaae8",
        "outputId": "4aff4ee0-a8fb-4d96-a6e3-c351ed123483"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(name='models/gemini-1.0-pro-latest',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro Latest',\n",
            "      description=('The best model for scaling across a wide range of tasks. This is the latest '\n",
            "                   'model.'),\n",
            "      input_token_limit=30720,\n",
            "      output_token_limit=2048,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.9,\n",
            "      max_temperature=None,\n",
            "      top_p=1.0,\n",
            "      top_k=None)\n",
            "Model(name='models/gemini-1.0-pro',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro',\n",
            "      description='The best model for scaling across a wide range of tasks',\n",
            "      input_token_limit=30720,\n",
            "      output_token_limit=2048,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.9,\n",
            "      max_temperature=None,\n",
            "      top_p=1.0,\n",
            "      top_k=None)\n",
            "Model(name='models/gemini-pro',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro',\n",
            "      description='The best model for scaling across a wide range of tasks',\n",
            "      input_token_limit=30720,\n",
            "      output_token_limit=2048,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.9,\n",
            "      max_temperature=None,\n",
            "      top_p=1.0,\n",
            "      top_k=None)\n",
            "Model(name='models/gemini-1.0-pro-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
            "      description=('The best model for scaling across a wide range of tasks. This is a stable '\n",
            "                   'model that supports tuning.'),\n",
            "      input_token_limit=30720,\n",
            "      output_token_limit=2048,\n",
            "      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
            "      temperature=0.9,\n",
            "      max_temperature=None,\n",
            "      top_p=1.0,\n",
            "      top_k=None)\n",
            "Model(name='models/gemini-1.0-pro-vision-latest',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro Vision',\n",
            "      description='The best image understanding model to handle a broad range of applications',\n",
            "      input_token_limit=12288,\n",
            "      output_token_limit=4096,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.4,\n",
            "      max_temperature=None,\n",
            "      top_p=1.0,\n",
            "      top_k=32)\n",
            "Model(name='models/gemini-pro-vision',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro Vision',\n",
            "      description='The best image understanding model to handle a broad range of applications',\n",
            "      input_token_limit=12288,\n",
            "      output_token_limit=4096,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.4,\n",
            "      max_temperature=None,\n",
            "      top_p=1.0,\n",
            "      top_k=32)\n",
            "Model(name='models/gemini-1.5-pro-latest',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Pro Latest',\n",
            "      description='Mid-size multimodal model that supports up to 2 million tokens',\n",
            "      input_token_limit=2000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64)\n",
            "Model(name='models/gemini-1.5-pro-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Pro 001',\n",
            "      description='Mid-size multimodal model that supports up to 2 million tokens',\n",
            "      input_token_limit=2000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64)\n",
            "Model(name='models/gemini-1.5-pro-002',\n",
            "      base_model_id='',\n",
            "      version='002',\n",
            "      display_name='Gemini 1.5 Pro 002',\n",
            "      description='Mid-size multimodal model that supports up to 2 million tokens',\n",
            "      input_token_limit=2000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=40)\n",
            "Model(name='models/gemini-1.5-pro',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Pro',\n",
            "      description='Mid-size multimodal model that supports up to 2 million tokens',\n",
            "      input_token_limit=2000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64)\n",
            "Model(name='models/gemini-1.5-pro-exp-0801',\n",
            "      base_model_id='',\n",
            "      version='exp-0801',\n",
            "      display_name='Gemini 1.5 Pro Experimental 0801',\n",
            "      description='Mid-size multimodal model that supports up to 2 million tokens',\n",
            "      input_token_limit=2000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64)\n",
            "Model(name='models/gemini-1.5-pro-exp-0827',\n",
            "      base_model_id='',\n",
            "      version='exp-0827',\n",
            "      display_name='Gemini 1.5 Pro Experimental 0827',\n",
            "      description='Mid-size multimodal model that supports up to 2 million tokens',\n",
            "      input_token_limit=2000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64)\n",
            "Model(name='models/gemini-1.5-flash-latest',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Flash Latest',\n",
            "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
            "      input_token_limit=1000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64)\n",
            "Model(name='models/gemini-1.5-flash-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Flash 001',\n",
            "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
            "      input_token_limit=1000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64)\n",
            "Model(name='models/gemini-1.5-flash-001-tuning',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Flash 001 Tuning',\n",
            "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
            "      input_token_limit=16384,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64)\n",
            "Model(name='models/gemini-1.5-flash',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Flash',\n",
            "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
            "      input_token_limit=1000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64)\n",
            "Model(name='models/gemini-1.5-flash-exp-0827',\n",
            "      base_model_id='',\n",
            "      version='exp-0827',\n",
            "      display_name='Gemini 1.5 Flash Experimental 0827',\n",
            "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
            "      input_token_limit=1000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64)\n",
            "Model(name='models/gemini-1.5-flash-8b-exp-0827',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Flash 8B Experimental 0827',\n",
            "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
            "      input_token_limit=1000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=40)\n",
            "Model(name='models/gemini-1.5-flash-8b-exp-0924',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Flash 8B Experimental 0924',\n",
            "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
            "      input_token_limit=1000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=40)\n",
            "Model(name='models/gemini-1.5-flash-002',\n",
            "      base_model_id='',\n",
            "      version='002',\n",
            "      display_name='Gemini 1.5 Flash 002',\n",
            "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
            "      input_token_limit=1000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helping function"
      ],
      "metadata": {
        "id": "ZDV1o0wPhMYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this function is used to enhance the printing of the propts of the model\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  display(Markdown(textwrap.indent(text, '> ', predicate=lambda _: True)))\n",
        "  # return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n"
      ],
      "metadata": {
        "id": "hv0lo12WZJPH"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pro and flash models"
      ],
      "metadata": {
        "id": "vVo44S6phPRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the latest content generative models from Gemini\n",
        "\n",
        "model_pro = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-001\",google_api_key=userdata.get('Gemini_API'),\n",
        "                             temperature=0.2)\n",
        "\n",
        "\n",
        "model_flash = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-001\",google_api_key=userdata.get('Gemini_API'),\n",
        "                             temperature=0.2)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YpWi7GizZ4Vq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to perform cleaning for the text\n",
        "\n",
        "def clean_text(text):\n",
        "\n",
        "    # replace multiple periods ('..') with a single space\n",
        "    text = re.sub(r'\\.{2,}', ' ', text)\n",
        "    # replace newline characters with a space\n",
        "    text = text.replace('\\n', ' ')\n",
        "    # remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "SpxHSd5hszY0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create chunks"
      ],
      "metadata": {
        "id": "aVVeVkqfhUmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# in the following function is used to create chunks of the text form .txt and .pdf files\n",
        "\n",
        "def Create_Chunks(directory_path, file_type, all_texts, chunk_size=700):\n",
        "    # Iterate through each file in the directory\n",
        "    for filename in os.listdir(directory_path):\n",
        "        if filename.endswith(file_type):  # Check if the file matches the given file type\n",
        "            file_path = os.path.join(directory_path, filename)\n",
        "\n",
        "            if file_type == \".pdf\":\n",
        "                # Load the PDF and split it into pages using PyPDFLoader\n",
        "                pdf_loader = PyPDFLoader(file_path)\n",
        "                pages = pdf_loader.load_and_split()\n",
        "\n",
        "                # Join all the pages into a single context string\n",
        "                context = \"\\n\\n\".join(str(p.page_content) for p in pages)\n",
        "\n",
        "            elif file_type == \".txt\":\n",
        "                # For text files, read the content directly\n",
        "                with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                    context = file.read()\n",
        "\n",
        "            # Create a text splitter with the desired chunk size\n",
        "            text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=50)\n",
        "\n",
        "            # Split the content into smaller chunks\n",
        "            texts = text_splitter.split_text(context)\n",
        "\n",
        "            # Append the split texts to the main list\n",
        "            all_texts.extend(texts)\n",
        "\n",
        "    print(\"Dividing process is done!\")\n",
        "    return all_texts\n"
      ],
      "metadata": {
        "id": "Qxrn9NjwZ3rD"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the txt and pdf files to use them in the rag"
      ],
      "metadata": {
        "id": "CiUkugJBhZo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#download the .zip file using gdown\n",
        "!gdown 1uXsgA5GzQPKDLt7DLqSS1TvJHEpXFI9C -O all_downloaded_file.zip\n",
        "\n",
        "#extract the .zip file\n",
        "!unzip -o all_downloaded_file.zip -d extracted_files\n",
        "\n",
        "if not os.path.exists('all_txt_files'):\n",
        "    os.makedirs('all_txt_files')\n",
        "\n",
        "if not os.path.exists('all_pdf_files'):\n",
        "    os.makedirs('all_pdf_files')\n",
        "\n",
        "for filename in os.listdir('extracted_files'):\n",
        "    # Check if the file is a PDF or a text file and move accordingly\n",
        "    if filename.endswith(\".pdf\"):\n",
        "        os.rename(os.path.join('extracted_files', filename), os.path.join('all_pdf_files', filename))\n",
        "    elif filename.endswith(\".txt\"):\n",
        "        os.rename(os.path.join('extracted_files', filename), os.path.join('all_txt_files', filename))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vy4rJC-1DsOK",
        "outputId": "112ff3f8-0cc4-4480-d285-a3a6354c9a5d"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  all_downloaded_file.zip\n",
            "  inflating: extracted_files/Copy of SpaceX Raptor3.txt  \n",
            "  inflating: extracted_files/Copy of SpaceX rocket Engine.txt  \n",
            "  inflating: extracted_files/Copy of spacex-falcon-9-data-sheet.pdf  \n",
            "  inflating: extracted_files/Copy of Starbase Overview.pdf  \n",
            "  inflating: extracted_files/Copy of ilide.info-elon-musk-the-success-story-of-real-life-iron-man-pr_9cda74e5d04c9d5909440d58af9af5bf.pdf  \n",
            "  inflating: extracted_files/Copy of The Real Reason SpaceX Developed The Raptor Engine!.txt  \n",
            "  inflating: extracted_files/Copy of The Journey of Elon Musk (Documentary).txt  \n",
            "  inflating: extracted_files/Copy of Raptor Engine.txt  \n",
            "  inflating: extracted_files/Copy of How SpaceX and NASA Plan To Build A Mars Colony!.txt  \n",
            "  inflating: extracted_files/Copy of SpaceX moonBase.txt  \n",
            "  inflating: extracted_files/Copy of SpaceX 2.pdf  \n",
            "  inflating: extracted_files/Copy of ilide.info-prj-21-spacex-pr_8b8d26fd851faebae3f5d242efd73cd4.pdf  \n",
            "  inflating: extracted_files/Copy of filtered_cc_news_articles.txt  \n",
            "  inflating: extracted_files/Copy of ilide.info-introduction-to-elon-musk-and-spacex-pr_5f1675fb8f07e35681615abad6bc8797.pdf  \n",
            "  inflating: extracted_files/Copy of GEOPLM-Siemens-PLM-NX-SpaceX-cs-Z10.pdf  \n",
            "  inflating: extracted_files/Copy of falcon-users-guide-2021-09.pdf  \n",
            "  inflating: extracted_files/Copy of filtered_wiki_articles.txt  \n",
            "  inflating: extracted_files/Copy of spacex_nasa_crs-5_presskit-105.pdf  \n",
            "  inflating: extracted_files/Copy of spacex_economies_of_scale_and_a_revolution_in_access_to_space.pdf  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## create text chunks"
      ],
      "metadata": {
        "id": "2bihiugDhjR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create text chunks\n",
        "\n",
        "texts =[]\n",
        "\n",
        "# create text chunks out of the pdf files\n",
        "texts, c1 = Create_Chunks(\"/content/all_txt_files\",\".txt\",texts) ,len(texts)\n",
        "print(\"\\nthe data from wiki, cc_new files & video files make up\", c1,\"chunk\")\n",
        "\n",
        "# create text chunks from the txt files\n",
        "texts ,c2 = Create_Chunks(\"/content/all_pdf_files\",\".pdf\",texts) ,len(texts)\n",
        "print(\"\\nthe data txt fies make up\",c2-c1,\"chunk\")\n",
        "\n",
        "print(\"\\nthe total chunks are: \",c2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-94ti1s5J1un",
        "outputId": "61ebdcc4-682f-4892-e08a-b8a8e700eefd"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dividing process is done!\n",
            "\n",
            "the data from wiki, cc_new files & video files make up 5724 chunk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pypdf._reader:Overwriting cache for 0 11250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dividing process is done!\n",
            "\n",
            "the data txt fies make up 697 chunk\n",
            "\n",
            "the total chunks are:  6421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test chunk\n",
        "texts[3684]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "GZNvwMhzKmJt",
        "outputId": "7144ba29-ac11-4cac-adc8-b194f3f9e491"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The EAP's one hundredth flight was performed during the 1987 Paris Air Show. During December 1987, the third phase of test flying commenced, after which an increasing emphasis was placed upon testing various technologies for the future Eurofighter Typhoon, such as the direct voice input interface and multi-function displays. The flight control laws would also be progressively refined, improving the handling and enabling the EAP to reach a recorded maximum speed of Mach 2.0 during its latter years of operation; the aircraft also demonstrated an ability to maintain controlled flight while flown at very high angles of attack, reportedly in excess of 35 degrees. The final round of test flights\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # this cell can be used if connected to  my drive\n",
        "# #create text chunks\n",
        "\n",
        "# texts =[]\n",
        "\n",
        "# # create text chunks out of the pdf files\n",
        "# texts, c1 = Create_Chunks(\"pdfsDataSet/\",\".pdf\",texts) ,len(texts)\n",
        "# print(\"\\nthe pdf files addded make up\", c1,\"chunk\")\n",
        "\n",
        "# # create text chunks from the wiki & cc_news articles\n",
        "# texts ,c2 = Create_Chunks(\"textDataSet/\",\".txt\",texts) ,len(texts)\n",
        "# print(\"\\nthe data from wiki & cc_new files addded make up\",c2-c1,\"chunk\")\n",
        "\n",
        "# #create text chunks from the video files\n",
        "# texts, c3 = Create_Chunks(\"soundDataSet\",\".txt\",texts) ,len(texts)\n",
        "# print(\"\\nthe data from videos files addded make up\", c3-c2,\"chunk\\nthe total chunks are: \",c3)\n"
      ],
      "metadata": {
        "id": "W5QHg3kys98C"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# create embeding by cohere\n",
        "# embeddings = CohereEmbeddings(cohere_api_key= userdata.get(\"cohere\") ,model=\"embed-english-v3.0\" ,user_agent= \"anything\")\n",
        "\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\",google_api_key=userdata.get('Gemini_API'))\n",
        "\n"
      ],
      "metadata": {
        "id": "0b6g62_8s96O"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the vector database and delete if existence one\n",
        "\n",
        "#initialize Chroma Client\n",
        "client = Client(Settings())\n",
        "\n",
        "# list all collections\n",
        "all_collections = client.list_collections()\n",
        "print(\"Existing Collections:\")\n",
        "for collection in all_collections:\n",
        "    print(f\"- {collection.name}\")\n",
        "\n",
        "# delete collections\n",
        "for collection in all_collections:\n",
        "    client.delete_collection(name=collection.name)\n",
        "    print(f\"Deleted collection: {collection.name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ar-XXULuQRZ",
        "outputId": "fb400c5c-c85b-422b-b803-45ef6f9483e5"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existing Collections:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create vector indexing"
      ],
      "metadata": {
        "id": "uqPD4yDRh0pi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# create the indexing and retreive the most k similar ones\n",
        "vector_index = Chroma.from_texts(texts, embeddings).as_retriever(search_kwargs={\"k\":7})\n"
      ],
      "metadata": {
        "id": "dNIK0fgauy5E"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# create the chain\n",
        "\n",
        "template = \"\"\"\n",
        "Use the following pieces of context to answer the question at the end.\n",
        "If you don't know the answer, just say that you don't know,\n",
        "and ask the user 'Would you like to ask Gemini 1.5 for this question?'.\n",
        "Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\n",
        "\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
        "\n",
        "\n",
        "# Run the chain for Gemini_pro 1.5 model\n",
        "qa_chain_pro = RetrievalQA.from_chain_type(\n",
        "    model_pro,\n",
        "    retriever=vector_index,\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        ")\n",
        "\n",
        "# Run the chain for Gemini_flash 1.5  model\n",
        "qa_chain_flash = RetrievalQA.from_chain_type(\n",
        "    model_flash,\n",
        "    retriever=vector_index,\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        ")"
      ],
      "metadata": {
        "id": "Dgpm92w3vSNF"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## the main RAG function"
      ],
      "metadata": {
        "id": "J37CICmdh53X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#this function to run the QA chain and handle answering\n",
        "\n",
        "def Run_My_Rag(question):\n",
        "\n",
        "    while True:\n",
        "        # Ask the user for input\n",
        "        # ask the user wich model to use\n",
        "        qa_chain = input(\"Please select which model to use for\\n Gemini_pro 1.5 press (1) & for Gemini_flash 1.5 press (2) \").strip()\n",
        "\n",
        "        if qa_chain == '1':\n",
        "            qa_chain = qa_chain_pro\n",
        "            break\n",
        "        elif qa_chain == '2':\n",
        "            qa_chain = qa_chain_flash\n",
        "            break\n",
        "        else:\n",
        "            print(\"Invalid input. Please enter '1' or '2'.\")\n",
        "\n",
        "    # run the QA chain with the user's question\n",
        "    result = qa_chain({\"query\": question})\n",
        "    to_markdown(result[\"result\"])\n",
        "\n",
        "    # Check if the response indicates that the answer isn't found\n",
        "    if \"Would you like to ask Gemini 1.5 for this question?\" in result['result']:\n",
        "\n",
        "        while True :\n",
        "          # If the user wants to ask Gemini, send the request there\n",
        "          # Ask the user for input\n",
        "          user_response = input(\"\\n\\nthe data provided did not mention this information('out-of-scope-question')\\n\\nWould you like to ask Gemini 1.5 (Generally) for this question?  (y/n): \").strip().lower()\n",
        "\n",
        "          if user_response == 'y':\n",
        "              gemini_answer = model_flash.invoke(question)\n",
        "              print(\"\\nGemini's Response:\\n\")\n",
        "              to_markdown(gemini_answer.content)\n",
        "              break\n",
        "          elif user_response == 'n':\n",
        "              print(\"Okay, let me know if there's anything else I can help with.\")\n",
        "              break\n",
        "          else:\n",
        "              print(\"Invalid input. Please enter 'y' or 'n'.\")\n",
        "\n",
        "    else:\n",
        "        # If the answer is found, ask for the citation\n",
        "        while True:\n",
        "          # Ask the user for input\n",
        "          user_response = input(\"if you would like to know the citation from your documents press (y)\").strip().lower()\n",
        "          if user_response == 'y':\n",
        "            print(\"\\nCitation:\\n\")\n",
        "            display(to_markdown(\" \".join(str(i.page_content) for i in result[\"source_documents\"][:3])))\n",
        "            break\n",
        "          else:\n",
        "            print(\"Okay, let me know if there's anything else I can help with.\")\n",
        "            break\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"langchain_google_genai\")\n"
      ],
      "metadata": {
        "id": "AdTE1ZzFwrFy"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some test cases"
      ],
      "metadata": {
        "id": "80uxwDLwh-e7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### you can select between 2 models Gemini_pro 1.5 press ==> (1) & for Gemini_flash 1.5 press ==> (2) 1\n",
        "### if the question is Out of scope, you can select to search in by Gemini Pro 1.5.\n",
        "### if the answer is in the information provided, you will be asked whether you would like to check the original chunks in this context"
      ],
      "metadata": {
        "id": "Q0k4wer1iJgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Run_My_Rag(\"how much do the empolyees of tesla earn every year? \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "id": "C-HB0HRY7Mj7",
        "outputId": "2dadf1a3-4975-4c8b-fbb3-99ac8fb18b32"
      },
      "execution_count": 164,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please select which model to use for\n",
            " Gemini_pro 1.5 press (1) & for Gemini_flash 1.5 press (2) 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> I don't know. Would you like to ask Gemini 1.5 for this question? \n> Thanks for asking! \n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "the data provided did not mention this information('out-of-scope-question')\n",
            "\n",
            "Would you like to ask Gemini 1.5 (Generally) for this question?  (y/n): y\n",
            "\n",
            "Gemini's Response:\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> I cannot provide you with specific salary figures for Tesla employees. \n> \n> Here's why:\n> \n> * **Confidentiality:** Salary information is considered private and confidential, both by companies and by law. \n> * **Wide Salary Ranges:** Salaries at Tesla (like most companies) vary greatly depending on:\n>     * **Job Title:** Engineers, software developers, factory workers, and administrative staff will all have different pay scales.\n>     * **Experience Level:** Entry-level vs. senior positions command different salaries.\n>     * **Location:** Cost of living and regional market factors influence pay.\n>     * **Performance:** Bonuses and stock options can significantly impact total compensation.\n> \n> **Where to Find General Information:**\n> \n> * **Glassdoor:** Websites like Glassdoor collect anonymous salary data from employees. While not perfectly accurate, they can give you a general range.\n> * **Salary Comparison Websites:** Sites like Salary.com or PayScale provide salary ranges based on job title, location, and experience.\n> * **Tesla's Career Page:** Tesla's own website might list salary ranges for open positions.\n> \n> **Remember:** The information you find online should be treated as a general guide. Actual salaries can vary significantly. \n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Run_My_Rag(\"how many liters of fuel does Falcon 9 consume for orbiting the earth per voyage\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "t0NE1SCG1IJW",
        "outputId": "41e55c28-1a90-4546-e9cc-fce578793e44"
      },
      "execution_count": 158,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please select which model to use for\n",
            " Gemini_pro 1.5 press (1) & for Gemini_flash 1.5 press (2) 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> I'm sorry, I cannot find the answer to how many liters of fuel Falcon 9 consumes for orbiting the earth per voyage. Would you like to ask Gemini 1.5 for this question? \n> \n> Thanks for asking! \n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "the data provided did not mention this information('out-of-scope-question')\n",
            "\n",
            "Would you like to ask Gemini 1.5 (Generally) for this question?  (y/n): n\n",
            "Okay, let me know if there's anything else I can help with.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Run_My_Rag(\"how many raptor engines in the starship\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "lSI3l0C7gV60",
        "outputId": "44917b6c-5024-4166-c832-bbcba518d299"
      },
      "execution_count": 165,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please select which model to use for\n",
            " Gemini_pro 1.5 press (1) & for Gemini_flash 1.5 press (2) 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> There are 36 Raptor Boost engines per Starship stack. \n> Thanks for asking! \n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "if you would like to know the citation from your documents press (y)y\n",
            "\n",
            "Citation:\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> The Raptor engine is the muscle of the SpaceX Starship program. Three dozen beating hearts that propelled the world's largest rocket into orbit and beyond, to the moon and eventually the planet Mars. And with that total of 36 Raptor Boost engines per Starship stack, there is a pretty heavy onus on SpaceX to build a whole lot of those engines in a very short period of time. It's actually become one of the most critical factors for the overall success of SpaceX and their mission to make space travel affordable and accessible and eventually allow the human race to become a multi-planetary species. So it's a lot of pressure and SpaceX engineers are rising to the occasion. They've already The Raptor engine is the muscle of the SpaceX Starship program. Three dozen beating hearts that propelled the world's largest rocket into orbit and beyond, to the moon and eventually the planet Mars. And with that total of 36 Raptor Boost engines per Starship stack, there is a pretty heavy onus on SpaceX to build a whole lot of those engines in a very short period of time. It's actually become one of the most critical factors for the overall success of SpaceX and their mission to make space travel affordable and accessible and eventually allow the human race to become a multi-planetary species. So it's a lot of pressure and SpaceX engineers are rising to the occasion. They've already engine's weight. According to SpaceX, Raptor 1 weighed 2.08 tons. Raptor 2 was 1.63 tons, and Raptor 3 now comes in at just 1.525 tons. While the reduction isn't as dramatic as some might have expected, it's still an impressive achievement. As for thrust, last year's test of Raptor 3 shocked the world when it was tested at 269 tons of thrust. However, after Musk's recent update we now know that Raptor 3's thrust has reached 280 tons at sea level and 306 tons in a vacuum. This increase in thrust will significantly impact the total power of starship, a topic we'll explore further later. What excites me the most about this upgrade is how it will revolutionize one of the key factors that has"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Run_My_Rag(\"what is the advance of using raptor3 in the new voyages of spaceX? answer in bullets\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "rOM36AF57ACf",
        "outputId": "7829edbe-6da7-4478-b922-8139c70605b9"
      },
      "execution_count": 166,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please select which model to use for\n",
            " Gemini_pro 1.5 press (1) & for Gemini_flash 1.5 press (2) 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Here are some advantages of using the Raptor 3 engine for SpaceX's new voyages:\n> \n> * **Faster Refurbishment:** The Raptor 3's streamlined design allows for quicker and more efficient refurbishment compared to older engines. \n> * **Increased Turnaround Speed:** This faster refurbishment could lead to Starships launching as frequently as, or even more often than, the Falcon 9.\n> * **Lower Production Costs:** The use of 3D printing in the Raptor 3's production significantly cuts down on manufacturing time and costs.\n> \n> Thanks for asking! \n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "if you would like to know the citation from your documents press (y)y\n",
            "\n",
            "Citation:\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> current engine version is challenging. But the streamlined design of the Raptor 3 will make refurbishment faster and more efficient. This could increase the Starships turnaround speed to match or even surpass that of the current Falcon 9. These advancements are essential for the long-term mission of Mars colonization. Given the varying distance between Earth and Mars, launches must be precisely timed making these missions exceptionally costly. The advantages of the Raptor 3 will be even more critical in this context. Before we get there, the Raptor 3 will play a pivotal role in SpaceX's upcoming developments, which includes several key changes. SpaceX has already begun producing V2 current engine version is challenging. But the streamlined design of the Raptor 3 will make refurbishment faster and more efficient. This could increase the Starships turnaround speed to match or even surpass that of the current Falcon 9. These advancements are essential for the long-term mission of Mars colonization. Given the varying distance between Earth and Mars, launches must be precisely timed making these missions exceptionally costly. The advantages of the Raptor 3 will be even more critical in this context. Before we get there, the Raptor 3 will play a pivotal role in SpaceX's upcoming developments, which includes several key changes. SpaceX has already begun producing V2 the engine from external impacts is no longer necessary. Instead, advanced cooling systems will manage the engine's heat during operation. In production, SpaceX continues to leverage 3D printing technology. Musk confirmed, many of them are 3D metal printed into the wall of the part. This technology, now a staple in the industry, has drastically improved production speed. First seen in the transition from Raptor 1 to Raptor 2, with Raptor 3, SpaceX continues to push the boundaries of what's possible in rocket engine design and production. The new upgrades have given Raptor 3 several significant advantages. But before we dive into these, please like, share the video and subscribe to our"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Run_My_Rag(\"what is the percent the employees in the spaceX company are mecahnical engineers\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 847
        },
        "id": "5iT57wAdXnBg",
        "outputId": "4964cbc7-37ac-4a28-c7ff-47d0bd70e1c2"
      },
      "execution_count": 167,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please select which model to use for\n",
            " Gemini_pro 1.5 press (1) & for Gemini_flash 1.5 press (2) 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> 24.9% of SpaceX employees majored in Mechanical Engineering. \n> \n> Thanks for asking! \n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "if you would like to know the citation from your documents press (y)y\n",
            "\n",
            "Citation:\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Personnel  \n>   *Total employment ~ 12,000 employees 49.8% of SpaceX \n> employees are White\n>   *86.3% male employees\n>   *13.7% female employees \n>   *38% are aged from 30 to 40 years old \n>   *Most (38.9%) employees earn around $40,000 to $60,000 \n> each year\n>   *Most hold the following degrees:\n>   * 54.7% have a Bachelor’s Degree\n>   *19.1% have an Associate Degree \n>   *10.6% have a Master’s Degree \n>   *8.0% have a High School Diploma\n>   *1.6% have a Doctorate Degree  *Most prominent employees’ majors :  \n>   *24.9% have a major in Mechanical Engineering \n>   *15% have a major in Business \n>   *10.6%  have a major in Aerospace Engineering\n>   * 8.1% have a major in Electrical Engineering \n>   * 5.3% have a major in Aviation Personnel  \n>   *Total employment ~ 12,000 employees 49.8% of SpaceX \n> employees are White\n>   *86.3% male employees\n>   *13.7% female employees \n>   *38% are aged from 30 to 40 years old \n>   *Most (38.9%) employees earn around $40,000 to $60,000 \n> each year\n>   *Most hold the following degrees:\n>   * 54.7% have a Bachelor’s Degree\n>   *19.1% have an Associate Degree \n>   *10.6% have a Master’s Degree \n>   *8.0% have a High School Diploma\n>   *1.6% have a Doctorate Degree  *Most prominent employees’ majors :  \n>   *24.9% have a major in Mechanical Engineering \n>   *15% have a major in Business \n>   *10.6%  have a major in Aerospace Engineering\n>   * 8.1% have a major in Electrical Engineering \n>   * 5.3% have a major in Aviation *Space Exploration Technologies Corp. (doing business as SpaceX) is an American aerospace manufacturer, a provider of space transportation services, and a communications corporation headquartered in Hawthorne, California. SpaceX was founded in 2002 by Elon Musk with the goal of reducing space transportation costs to enable the colonization of Mars. SpaceX manufactures the Falcon 9 and Falcon Heavy launch vehicles, several rocket engines, Cargo Dragon, crew spacecraft, and Starlink communications satellites. SpaceX's achievements include the first privately funded liquid-propellant rocket to reach orbit around Earth, the first private company to successfully launch, orbit, and recover a"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Run_My_Rag(\"what Falcon launch vehicles were designed from the beginning for\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "LYz0tFxJa6Dr",
        "outputId": "d1da6bb0-9e64-4c4f-dd22-77b2088adf40"
      },
      "execution_count": 143,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please select which model to use for\n",
            " Gemini_pro 1.5 press (1) & for Gemini_flash 1.5 press (2) 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Falcon launch vehicles were designed from the beginning to meet NASA human-rated safety margins. \n> Thanks for asking! \n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "if you would like to know the citation from your documents press (y)y\n",
            "\n",
            "Citation:\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> launches for both commercial and government clients.  \n>  \n> Designed to safely transport crew.  Like the Dragon spacecraft, Falcon \n> 9 was designed from the outset to transport crew to space.  \n>  \n> Mission success.  Falcon 9 has achieved 100% primary mission success \n> on its flights to date, including routine flights to the International Space Station and most recently the successful \n> September 2014 launch of the CRS-4 mission.  \n>  \n> Why “Falcon”?  Falcon 9 is named for the Millennium Falcon in the “Star Wars” movies. The number 9 refers to the nine \n> Merlin engines that power Falcon 9’s first stage; one Merlin vacuum engine powers the second stage. launches for both commercial and government clients.  \n>  \n> Designed to safely transport crew.  Like the Dragon spacecraft, Falcon \n> 9 was designed from the outset to transport crew to space.  \n>  \n> Mission success.  Falcon 9 has achieved 100% primary mission success \n> on its flights to date, including routine flights to the International Space Station and most recently the successful \n> September 2014 launch of the CRS-4 mission.  \n>  \n> Why “Falcon”?  Falcon 9 is named for the Millennium Falcon in the “Star Wars” movies. The number 9 refers to the nine \n> Merlin engines that power Falcon 9’s first stage; one Merlin vacuum engine powers the second stage. by servicing and inspecting hardware as well as incorporating lessons that can only be learned from flight . \n>  \n> The Falcon launch vehicle s were designed  from the beginning to meet  NASA human -rated safety margin s. We continue \n> to push the limits of rocket technology as we design the safest crew transportation system ever flown while \n> simultaneously advancing toward fully reusable launch vehicles. Our emphasis on safety has led to  advancements such \n> as increased stru ctural factors of safety , greater redundancy and rigorous fault mitigation. Because SpaceX produces \n> one Falcon core vehicle, satellite c ustomers benefit from the high design standards required to safely transport crew."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Run_My_Rag(\"where ELON MUSK where educated?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "6AOdOfBkfnk5",
        "outputId": "26763d86-0936-4109-be20-bf556f4b6f21"
      },
      "execution_count": 168,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please select which model to use for\n",
            " Gemini_pro 1.5 press (1) & for Gemini_flash 1.5 press (2) 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Elon Musk was educated at Queen's University in Kingston, Ontario, and the University of Pennsylvania. \n> \n> Thanks for asking! \n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "if you would like to know the citation from your documents press (y)y\n",
            "\n",
            "Citation:\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> the United States from Canada, Musk applied for a Canadian passport through his Canadian-born mother. While awaiting the documentation, he attended the University of Pretoria for five months; this allowed him to avoid mandatory service in the South African military. Musk arrived in Canada in June 1989, and lived with a second-cousin in Saskatchewan for a year, working odd jobs at a farm and lumber-mill. In 1990, he entered Queen's University in Kingston, Ontario. Two years later, he transferred to the University of Pennsylvania, where he graduated in 1995 with a Bachelor of Science degree in economics and a Bachelor of Arts degree in physics. In 1994, Musk held two internships in Silicon the United States from Canada, Musk applied for a Canadian passport through his Canadian-born mother. While awaiting the documentation, he attended the University of Pretoria for five months; this allowed him to avoid mandatory service in the South African military. Musk arrived in Canada in June 1989, and lived with a second-cousin in Saskatchewan for a year, working odd jobs at a farm and lumber-mill. In 1990, he entered Queen's University in Kingston, Ontario. Two years later, he transferred to the University of Pennsylvania, where he graduated in 1995 with a Bachelor of Science degree in economics and a Bachelor of Arts degree in physics. In 1994, Musk held two internships in Silicon to Canada at age 17 to avoid conscription. He was enrolled at Queen's University and transferred to the University of Pennsylvania two years later, where he received a bachelor's degree in economics and physics. He moved to California in 1995 to attend Stanford University but decided instead to pursue a business career, co-founding the web software company Zip2 with his brother Kimbal. The startup was acquired by Compaq for $307 million in 1999. The same year, Musk co-founded online bank X.com, which merged with Confinity in 2000 to form PayPal. The company was bought by eBay in 2002 for $1.5 billion. In 2002, Musk founded SpaceX, an aerospace manufacturer and space transport services"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Run_My_Rag(\"what is Crew-9 astronaut mission\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "UJjaGQBlXayl",
        "outputId": "4c317c73-002e-41c5-f034-cc11e5a5d740"
      },
      "execution_count": 169,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please select which model to use for\n",
            " Gemini_pro 1.5 press (1) & for Gemini_flash 1.5 press (2) 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> I don't know. Would you like to ask Gemini 1.5 for this question? \n> Thanks for asking! \n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "the data provided did not mention this information('out-of-scope-question')\n",
            "\n",
            "Would you like to ask Gemini 1.5 (Generally) for this question?  (y/n): n\n",
            "Okay, let me know if there's anything else I can help with.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Run_My_Rag(\"what is the World’s Tallest Rocket Launch and Catch Tower?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "GiLXU7jlqS3-",
        "outputId": "6ea70b87-ae1e-4d82-d619-0318b4a19a88"
      },
      "execution_count": 170,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please select which model to use for\n",
            " Gemini_pro 1.5 press (1) & for Gemini_flash 1.5 press (2) 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> The World’s Tallest Rocket Launch and Catch Tower is SpaceX's launch and catch tower at Starbase. \n> \n> Thanks for asking! \n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "if you would like to know the citation from your documents press (y)n\n",
            "Okay, let me know if there's anything else I can help with.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Run_My_Rag(\"when the World’s Tallest Rocket Launch and Catch Tower was build?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "vm56xR7eqcOY",
        "outputId": "f36d86ff-5f40-4b79-8a2f-772419e889ed"
      },
      "execution_count": 171,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please select which model to use for\n",
            " Gemini_pro 1.5 press (1) & for Gemini_flash 1.5 press (2) 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> The text states that SpaceX broke ground on the launch and catch tower at Starbase in 2021. \n> \n> Thanks for asking! \n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "if you would like to know the citation from your documents press (y)y\n",
            "\n",
            "Citation:\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Moon, and travel to Mars and beyond.  \n> World’s Tallest Rocket  Launch and Catch Tower  \n> In 2021, SpaceX broke ground on the launch and catch tower at Starbase. The tower rises ~480 \n> feet in height —the tallest launch tower in the world —and it is designed to support launch, \n> vehicle integration, and catch of the Super Heavy rocket booster . Catching the booster reduces \n> mass from the launch vehicle, moves hardware complexity to the ground, and enables rapid \n> reuse of the rocket. Moon, and travel to Mars and beyond.  \n> World’s Tallest Rocket  Launch and Catch Tower  \n> In 2021, SpaceX broke ground on the launch and catch tower at Starbase. The tower rises ~480 \n> feet in height —the tallest launch tower in the world —and it is designed to support launch, \n> vehicle integration, and catch of the Super Heavy rocket booster . Catching the booster reduces \n> mass from the launch vehicle, moves hardware complexity to the ground, and enables rapid \n> reuse of the rocket. *Space Launch Complex 17 (SLC-17), previously designated Launch Complex 17 (LC-17), was a launch site at Cape Canaveral Air Force Station (CCAFS), Florida used for Thor and Delta launch vehicles launches between 1958 and 2011. It was built in 1956 for use with the PGM-17 Thor missile, the first operational ballistic missile in the arsenal of the United States. More recently the launch complex has been used for vehicles in the Delta launch vehicle family, derived from the Thor missile, to launch probes to the Moon and planets, solar observatories and weather satellites. SLC-17 features two expendable launch vehicle (ELV) launch pads, 17A and 17B. The pads were operated by the 45th Space Wing"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Run_My_Rag(\"according to elun musk what is The best moonbase?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "j5luYi8qq0k8",
        "outputId": "59a5ae02-f763-484b-9332-7874e8cd3499"
      },
      "execution_count": 172,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please select which model to use for\n",
            " Gemini_pro 1.5 press (1) & for Gemini_flash 1.5 press (2) 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> According to the text, Elon Musk would say the best moonbase is **no moonbase**. \n> \n> Thanks for asking! \n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "if you would like to know the citation from your documents press (y)y\n",
            "\n",
            "Citation:\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> The best moonbase is no moonbase. That's the kind of thing that Elon Musk would probably say if he was asked about how to build the first permanent settlement on the moon. And it may sound like typical business guru nonsense, but this particular muskism is exactly what we need to actually move forward with establishing a human presence on the moon. This is a massive project that will require the engineering efficiency and design minimalism that SpaceX and Tesla have become famous for. A true first principles approach. This is how SpaceX plans to build the first moonbase. Now, the easy answer to the problem is that SpaceX doesn't need to build the moonbase because they're already building a The best moonbase is no moonbase. That's the kind of thing that Elon Musk would probably say if he was asked about how to build the first permanent settlement on the moon. And it may sound like typical business guru nonsense, but this particular muskism is exactly what we need to actually move forward with establishing a human presence on the moon. This is a massive project that will require the engineering efficiency and design minimalism that SpaceX and Tesla have become famous for. A true first principles approach. This is how SpaceX plans to build the first moonbase. Now, the easy answer to the problem is that SpaceX doesn't need to build the moonbase because they're already building a or disaster. I think it might be one of those things that we just have to assume that robots will be able to do it for us, and we put our faith in the Tesla bot. But assuming that we can unlock the entire 50 meter length and 9 meter width of the starship body, and kid it out with everything that we need to survive and explore 400,000 km away from home, then at that point, we have ourselves one hell of a moon base. In theory, we want to maintain the most simple, yet effective interior layout possible, something that maximizes comfort and ease of use. So in my mind at least, it makes the most sense to go with an open concept starship moon base. We make one level floor from front to back,"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}